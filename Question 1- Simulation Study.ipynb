{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homewok 1: Simulation Study\n",
    "\n",
    "Welcome to the course **AI and Deep learning**!\n",
    "\n",
    "Since most of you are not very familiar with deep learning, let us first review some basic concepts in traditional statistic courses. Specifically, the first homework help you to code up a linear regression model, and we are going to generate a training data, visualize the data, estimate the model parameters, and make inference about the model parameters. Hope you enjoy the first homework!  \n",
    "\n",
    "**Learning Goal**: In this homework, we are going to conduct a simple simulation study based on a linear regression. After this homework, you will know:\n",
    "\n",
    "* Basic tips about how to setup a statistic simulation study.\n",
    "* How to decompose a certain task into severl small functions.\n",
    "* How to estimate the model parameters based on a linear regression model.\n",
    "* How to obtain the coverage rates based on certain asymptotic results.\n",
    "* How to do vectorization based on a linear regression model. We also compare the computation efficiency between summation and vectorization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "* [1 - Packages](#1)\n",
    "* [2 - Generate a training dataset](#2)\n",
    "* [3 - Parameter estimation](#3) \n",
    "* [4 - Statistical inference](#4)\n",
    "* [5 - Computation efficiency](#5)\n",
    "* [6 - Additional homework](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1- Packages\n",
    "\n",
    "In order to finish a task, we need commands from certain **Python** packages. Thus, the first thing to do is to import the packages we need. One of the commonly used package is **numpy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plots\n",
    "import scipy.stats # for quantile calculation when we consider coverage rates\n",
    "import time # for computation efficiency comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Generate a training dataset\n",
    "\n",
    "The main difference between a simulation study and a real data application is that a model is pre-specified for a simulation study. Then, we can generate different training datasets from that model. **In order to guarantee that our simulation results are reproducible, we need to control the random seed.** That is, after controlling the seed, others can generate the **SAME** random variables as we did, so our simulation results can be reproduced.\n",
    "\n",
    "Since we are using the package **numpy** (or **np**) to generate random variables, the following command is useful:\n",
    "* np.random.seed(xxxx) # xxxx is the seed to generate random numbers. \n",
    "\n",
    "The following is a simple example, which may be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "np.random.seed(1)\n",
    "a = np.random.normal(1) # the first random variable generated after the seed.\n",
    "print(a)\n",
    "b = np.random.normal(1) # the second random variable generated after the seed.\n",
    "print(b)\n",
    "\n",
    "np.random.seed(1)\n",
    "c = np.random.normal(1) # the first random variable generated after the seed. It should equal to a.\n",
    "print(c)\n",
    "print(a==c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is your turn to generate a training dataset. Consider the following linear regression model \n",
    "\\begin{equation}\n",
    "y^{(i)}=b_0+w_0x^{(i)}+\\epsilon^{(i)}\\quad(i=1,\\ldots,n),\\tag{1}\\label{eq: model setup}\n",
    "\\end{equation}\n",
    "where $b_0=w_0=1$, $x^{(i)}\\sim N(2,2^2)$ and $\\epsilon^{(i)}\\sim N(0,1)$ for $i=1,\\ldots,n$.\n",
    "\n",
    "Your first job is to write a function to generate a training dataset of size $n$ with a random number $rn$. That is, compete the following function. (**DO NOT CHANGE THE EXISTING PARTS**) The following command may be useful, and check the help document for details:\n",
    "\n",
    "* `np.random.normal`: generate normally distributed random variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "# Provide your code between ``YOUR CODE BEGINS HERE (approximately 4 lines)'' and ``YOUR CODE ENDS''.\n",
    "def train_data_generation(n, rn):\n",
    "    # n: sample size\n",
    "    # rn: random seed\n",
    "    \n",
    "    # Step 1. Set random seed to be rn\n",
    "    # Step 2. Generate x of size n from a normal distribution with mean 2 and standard deviation 2\n",
    "    # Step 3. Generate \\epsilon of size n from a normal distribution with mean 2 and standard deviation 2\n",
    "    # Step 4. Generate y by (1)\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 4 lines)\n",
    "    np.random.seed()\n",
    "    x = \n",
    "    epsilon = \n",
    "    y = \n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    \n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize your data, you may would like to run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "x, y = train_data_generation(1000, 100)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"x values\")\n",
    "plt.ylabel(\"y values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Parameter estimation\n",
    "\n",
    "Denote $\\tilde{x}^{(i)} = (1,x^{(i)})^T$, $X=(\\tilde{x}^{(1)},\\ldots,\\tilde{x}^{(n)})^{T}\\in\\mathbb{R}^{n\\times2}$ and $Y=(y^{(1)},\\ldots,y^{(n)})^T$. Based on the normal equation, we know that an estimator of $(b_0,w_0)$ in (1) is \n",
    "$$\n",
    "(\\hat{b}_0,\\hat{w}_0) = \\left(\\sum_{i=1}^n \\tilde{x}^{(i)}(\\tilde{x}^{(i)})^T\\right)^{-1}\\sum_{i=1}^n \\tilde{x}^{(i)}y_i = (X^TX)^{-1}X^TY. \\tag{2}\n",
    "$$\n",
    "The first equality corresponds to the 'summation method', while the last corresponds to vectorization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we consider the 'summation method', and your job is to write a function based on the first equation of (2). The following command may be useful, and check the help document for details:\n",
    "* `np.concatenate`: concatenate two arrays\n",
    "* For two matrices A and B, the matrix multiplication is `A @ B`\n",
    "* `np.linalg.inv`: calculate the inverse of a matrix\n",
    "* `np.flatten`: obtain a 1d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def estimation_summation(x,y):\n",
    "    # x: the generated feature vector of length n\n",
    "    # y: the generated feature vector of length n\n",
    "    \n",
    "    # Step 1. Obtain the sample size\n",
    "    # Step 2. Augment the feature vector with the intercept term, check the relationship between \\tilde{x} and x\n",
    "    # Step 3. Initialize 'xx' by a 2X2 zero matrix\n",
    "    # Step 4. Initialize 'xy' by a 2X1 zero matrix\n",
    "    # Step 5. Calculate the summations for 'xx' and 'xy' based on the first equation of (2)\n",
    "    # Step 6. Calculate the inverse of 'xx'\n",
    "    # Step 7. Obtain the estimator as the first equation of (2)\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 10 lines)\n",
    "    n = \n",
    "    aug_x = \n",
    "    xx = \n",
    "    xy = \n",
    "    \n",
    "    for i in :\n",
    "        example_i = \n",
    "        xx += \n",
    "        xy += \n",
    "    \n",
    "    xx_inv = \n",
    "    par_est = \n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    return par_est.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider vectorization, and complete the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def estimation_vectorization(x,y):\n",
    "    # x: the generated feature vector of length n\n",
    "    # y: the generated feature vector of length n\n",
    "    \n",
    "    # Step 1. Obtain the sample size\n",
    "    # Step 2. Augment the feature vector with the intercept term, check the relationship between \\tilde{x} and x\n",
    "    # Step 3. Obtain 'xx' by X^TX, where X is the augmented matrix of size nX2\n",
    "    # Step 4. Obtain 'xy' by X^TY, where the shape of Y is nX1 \n",
    "    # Step 5. Calculate the inverse of 'xx'\n",
    "    # Step 6. Obtain the estimator as the second equation of (2)\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 6 lines)\n",
    "    n = \n",
    "    aug_x = \n",
    "    \n",
    "    xx = \n",
    "    xy = \n",
    "   \n",
    "    xx_inv = \n",
    "    par_est = \n",
    "    ### YOUR CODE ENDS\n",
    "\n",
    "    return par_est.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "print(estimation_summation(x,y))\n",
    "print(estimation_vectorization(x,y))\n",
    "print('The two estimators above should be identical')\n",
    "print('The true parameters are 1 and 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Statistical inference\n",
    "Usually, we conduct 1\\,000 Monte Carlo simulations. That is, we generate the training datasets of size $n$ independently 1\\,000 times. Then, for each generated training dataset, we estimate the model parameters $(b_0,w_0)$. Then, we pool them together to check their bias, variance and MSE. If we have more than one estimation methods, we can compare when in terms of bias, variance and MSE. In this homework, even though we have two different methods to estimate the model parameters, their results should be identical. Thus, we only consider the vectorization method, and we would compare the computaion efficiency of the two estimation methods in the next section.\n",
    "\n",
    "We first consider the case with $n=1\\,000$, and record all the estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "n = 1000\n",
    "par_result = np.zeros((1000,2))\n",
    "\n",
    "for i in range(1000):\n",
    "    x, y = train_data_generation(n=n, rn=i) # the random seed is set to be i\n",
    "    par_result[i,:] = estimation_vectorization(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we check the bias, variance and MSE for the two estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "bias_est = np.mean(par_result,axis = 0)-1\n",
    "var_est = np.var(par_result,axis = 0)\n",
    "mse_est = bias_est**2 + var_est\n",
    "print('The bias for estimating b0 and w0 is')\n",
    "print(bias_est)\n",
    "print('The variance for estimating b0 and w0 is')\n",
    "print(var_est)\n",
    "print('The mse for estimating b0 and w0 is')\n",
    "print(mse_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please notice that under the model setup (1), the theoretical variance of the estimator $(\\hat{b}_0,\\hat{w}_0)$ conditional on the generated features should be \n",
    "$$\n",
    "(X^TX)^{-1}\\sigma^2,\n",
    "$$\n",
    "where $\\sigma^2=1$ is the variance of the error term $\\epsilon$ in (1). By the law of large numbers, $(X^TX)$ does not change too much for each Monte Carlo simulation, especially when $n$ is large enough. Thus, one way to check our code is to see whether the Monte Carlo variance of the two estimator matches the theoretical one approximately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we consider a variance estimator, and $\\hat{\\sigma}^2$ can be estimated by the sample variance of $\\hat{\\epsilon}^{(i)}=y^{(i)} - \\hat{b}_0-\\hat{w}_0x^{(i)}$ for $i=1,\\ldots,n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def se_est(x,y):\n",
    "    # x: the generated feature vector of length n\n",
    "    # y: the generated feature vector of length n\n",
    "    \n",
    "    # Step 1. Obtain the estimator of (b_0, w_0)\n",
    "    # Step 2. Obtain the errors\n",
    "    # Step 3. Obtain \\hat{\\sigma}^2\n",
    "    # Step 4. Augment the feature vector with the intercept term, check the relationship between \\tilde{x} and x\n",
    "    # Step 5. Obtain 'xx' by X^TX, where X is the augmented matrix of size nX2\n",
    "    # Step 6. Obtain the variance estimator based on the above result.\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 6 lines)\n",
    "    est_par = \n",
    "    error_est = \n",
    "    sigma2_est = \n",
    "    \n",
    "    aug_x = \n",
    "    xx = \n",
    "    sd_par = \n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    \n",
    "    return sd_par\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check whether our function is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "n = 1000\n",
    "sd_result = np.zeros((1000,2))\n",
    "\n",
    "for i in range(1000):\n",
    "    x, y = train_data_generation(n=n, rn=i) # the random seed is set to be i\n",
    "    sd_result[i,:] = se_est(x,y)\n",
    "print('Your estimated results are:')\n",
    "print(np.mean(sd_result,axis = 0))\n",
    "print('Approximately, the true values are')\n",
    "print(np.array([0.04361731, 0.01530787]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that under our model setup, the following asymptotic result holds\n",
    "$$\n",
    "(X^TX)(\\sigma^2)^{-1}((\\hat{b}_0,\\hat{w}_0) - (b_0,w_0))^T\\to N((0,0)^T,I_2)\n",
    "$$\n",
    "in distribution as $n\\to\\infty$, where $I_2$ is a $2\\times 2$ identity matrix. By this result, we can also check the coverage rates of two-sided 95\\% confidence intervals \n",
    "$$\n",
    "(\\hat{b}_0 - q_{0.975}\\hat{\\sigma}_b,\\hat{b}_0 - q_{0.025}\\hat{\\sigma}_b)\\\\\n",
    "(\\hat{w}_0 - q_{0.975}\\hat{\\sigma}_w,\\hat{w}_0 - q_{0.025}\\hat{\\sigma}_w),\n",
    "$$\n",
    "where $q_\\alpha$ is the $\\alpha$-th quantile of a standard normal distribution, and $\\hat{\\sigma}_b$ and $\\hat{\\sigma}_w$ are the estimated standard error of the two estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your results are very close to the desired value, you can move to the coverage rates. For each simulated training dataset, we need to check whether the constructed confidence interval covers the true value or not. The following command may be useful, \n",
    "\n",
    "* `scipy.stats.norm.ppf`: obtain quantiles of a standard normal distribution\n",
    "* `and`: logic operator for 'and'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def cr_indicator(x,y,alpha):\n",
    "    # x: the generated feature vector of length n\n",
    "    # y: the generated feature vector of length n\n",
    "    # alpha: significance level. For example, alpha=0.05 corresponds to a 95% two-sided confidence interval.\n",
    "\n",
    "    # Step 1. Obtain (1-\\alpha/2)th quantile of a standard normal distribution.\n",
    "    # Step 2. Obtain parameter estimation \n",
    "    # Step 3. Obtain standard error estimation\n",
    "    # Step 4. Generate the indicator whether the true value of b_0 lies in the confidence interval\n",
    "    # Step 5. Generate the indicator whether the true value of b_0 lies in the confidence interval\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 5 lines)\n",
    "    quan_normal = \n",
    "    est_par = \n",
    "    est_se = \n",
    "    \n",
    "    ind_b = \n",
    "    ind_w = \n",
    "    ### YOUR CODE ENDS    \n",
    "\n",
    "    \n",
    "    return np.array([ind_b, ind_w])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "cr_est = np.ones_like(par_result)-10 # Usually, we should have an NA matrix or a NULL matrix\n",
    "for i in range(1000):\n",
    "    x, y = train_data_generation(n=n, rn=i) # the random seed is set to be i\n",
    "    cr_est[i,:]  = cr_indicator(x, y, alpha = 0.05)\n",
    "print('Your coverage rates for the two parameters are:')    \n",
    "print(np.mean(cr_est, axis = 0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your results are close to $1-\\alpha = 0.95$, then your code is good.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Computation efficiency\n",
    "Even though the 'summation method' produces the same estimation results as the vectorization method, but its computation efficiency is pretty low, especially when the sample size is large. In this section, we compare the computation efficiency of the two methods. We still consider the case for $n=1\\,000$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "T1 = time.time()\n",
    "for i in range(1000):\n",
    "    x, y = train_data_generation(n=n, rn=i) # the random seed is set to be i\n",
    "    par_est = estimation_summation(x,y)\n",
    "T2 = time.time()\n",
    "print('The summation method takes about %s seconds' % ((T2 - T1)))\n",
    "\n",
    "T1 = time.time()\n",
    "for i in range(1000):\n",
    "    x, y = train_data_generation(n=n, rn=i) # the random seed is set to be i\n",
    "    par_est = estimation_vectorization(x,y)\n",
    "T2 = time.time()\n",
    "print('The vectorization method takes about %s seconds' % (T2 - T1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparison, we know that the vectorization method is much faster than the summation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Additional homework\n",
    "When you finish the above basic function, we consider the following additional homeworks. \n",
    "\n",
    "* Usually, when we conduct simulation studies, we may consider more than one setup. For simplicity, we only consider different setups for the sample size. Consider $n\\in \\{100, 300, 500, 1\\,000\\}$ and use figures to report the following aspects. Plese notice that for all figures, sample sizes index the x-axis. \n",
    "   \n",
    "   * In one figure, show the bias as the y-axis and comment your results. \n",
    "   * In one figure, show the variance as the y-axis and comment your results.\n",
    "   * In one figure, show the coverage rate for $b_0$ as the y-axis and comment your results.\n",
    "   * In one figure, show the coverage rate for $w_0$ as the y-axis and comment your results.\n",
    "   * In one figure, show the computation efficiency of the two estimation methods, and different colors should be used for different methods. Comment your results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
